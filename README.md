### PEFTEval

The repository contains the code for the paper “Comparison of Robustness and Performance: Parameter-Efficient vs. Full-Parameter Fine-Tuning”.





## Repository Overview  

There are several directories in this repo:
* [glue/](glue) contains the source code for evaluation AdvGLUE   
* [squad](squad) contains the source code for evaluation Adversarial SQuAD 
* [few-shot](scripts) contains the source code for few-shot learning base on llama
* [instruction fine-tuning](instruction fine-tuning) contains the source code for instruction fine-tuning

Use the following script to fine-tune Llama-2 series models on ViGGO, GSM8K and SQL Generation

https://github.com/ray-project/ray/tree/master/doc/source/templates/04_finetuning_llms_with_deepspeed



